{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNb8zElZpMsumYXqhpFO4xv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtabuena/Ephys_DataSets/blob/main/Analyze_BMX_HEK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5Bsqf_jeQjZ"
      },
      "outputs": [],
      "source": [
        "'Get Standard Modules'\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from scipy import stats\n",
        "import os\n",
        "from scipy.signal import butter,filtfilt\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "from IPython.display import clear_output\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import warnings\n",
        "import shutil\n",
        "from google.colab import files\n",
        "warnings.filterwarnings('ignore')\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "clear_output(wait=False)\n",
        "\n",
        "\n",
        "\n",
        "!pip install openpyxl\n",
        "!pip install XlsxWriter\n",
        "\n",
        "\n",
        "'''Get Repositories'''\n",
        "try: shutil.rmtree('/content/EphysLib')\n",
        "except: None\n",
        "\n",
        "\"run dtabuena's ephys notebooks\"\n",
        "!git clone https://github.com/dtabuena/EphysLib\n",
        "to_import = [\n",
        "            'ABF_Quality_Control.ipynb',\n",
        "            'Basic_Ephys.ipynb',\n",
        "            'Simple_ABF_tools.ipynb',\n",
        "            'fun_math.ipynb',\n",
        "            'importing_abfs_from_dropbox.ipynb',\n",
        "            'QC_recoding_dataframe.ipynb',\n",
        "            'Analyzers/input_resistance_analyzer.ipynb',\n",
        "            'Analyzers/gain_analyzer.ipynb',\n",
        "            'Analyzers/latencey_analyzer.ipynb',\n",
        "            'Analyzers/IV_analyzer.ipynb',\n",
        "            'Analyzers/Vm_analyzer.ipynb',\n",
        "            'Analyzers/membrane_analyzer.ipynb',\n",
        "            'Analyzers/rheobase_analyzer.ipynb',\n",
        "\n",
        "            'Ephys_wrapper.ipynb',\n",
        "            ]\n",
        "for i in to_import:\n",
        "    f = '/content/EphysLib/' + i\n",
        "    %run $f\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### quick import\n",
        "import urllib\n",
        "import json\n",
        "import matplotlib as mpl\n",
        "from matplotlib import rcParams\n",
        "def import_mpl_config(FS=6):\n",
        "    \"\"\" Load my default plotting parameters \"\"\"\n",
        "    if os.path.isfile(f'./mpl_config_FS{FS}.json'):\n",
        "        os.remove(f'./mpl_config_FS{FS}.json')\n",
        "    _ = urllib.request.urlretrieve('https://github.com/dtabuena/Resources/'\\\n",
        "                                   'raw//main/Matplotlib_Config/'\\\n",
        "                                   f'mpl_config_FS{FS}.json',\n",
        "                                   f'mpl_config_FS{FS}.json')\n",
        "    with open(f\"./mpl_config_FS{FS}.json\",'r') as import_file:\n",
        "        fig_config = json.load(import_file)\n",
        "    rcParams.update(fig_config)\n",
        "    _ = urllib.request.urlretrieve('https://github.com/dtabuena/Resources/raw/main/Fonts/arial.ttf','arial.ttf')\n",
        "    mpl.font_manager.fontManager.addfont('arial.ttf')\n",
        "    return fig_config\n",
        "_ = import_mpl_config()"
      ],
      "metadata": {
        "id": "3k_zR7QphuYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "file_name,_ = urllib.request.urlretrieve('https://www.dropbox.com/scl/fi/1yg80je83aqr68berui86/Before_After.csv?rlkey=k9pacq5t9u9icu1nkcnrhoad6&dl=1','before_after.csv')\n",
        "doses_df = pd.read_csv(file_name).set_index('Cell')\n",
        "display(doses_df.head(15))"
      ],
      "metadata": {
        "id": "iHdSeg2QT5nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = {'data_name': 'BMX',\n",
        "           'data_source': \"https://www.dropbox.com/scl/fo/2ps1mdb88490cgol95l3u/h?rlkey=trp33s4fhrl4pyg4h4k0jecwh&dl=1\",\n",
        "           'file_naming_scheme': ['Rec_date','GenoType','Cell_num','Cell_Type'],\n",
        "           }\n",
        "##2023x12x13_SLICK_c001_HEK_0001\n",
        "data_name = dataset['data_name']\n",
        "data_source = dataset['data_source']\n",
        "file_naming_scheme = dataset['file_naming_scheme']\n",
        "\n",
        "''' Gather and Catalog Source Data'''\n",
        "file_loc = get_drobox_folder_url(data_source, 'my_ephys_data_' + data_name)\n",
        "clear_output(wait=False)\n",
        "abf_recordings_df, protocol_set = catalogue_recs(file_loc,file_naming_scheme)\n",
        "print(protocol_set)"
      ],
      "metadata": {
        "id": "7tcKwC6keh7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('figs'): os.makedirs('figs')"
      ],
      "metadata": {
        "id": "95DCzbAThC4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "def measure_slick(abf,duration_ms = 10,to_plot=True):\n",
        "    i_chan = 0\n",
        "    duration_indx = int(duration_ms/1000*abf.sampleRate)\n",
        "    measure_epoch = get_epoch(abf,epoch=3)\n",
        "    stop_idx = measure_epoch['index'][\"stop\"]\n",
        "    start_idx = stop_idx - duration_indx\n",
        "    # if 2 in abf.channelList: i_chan = 2\n",
        "    I,V,T = analyze_currents(abf,start_idx,stop_idx,i_chan=i_chan)\n",
        "    return {'Ik':I,'Vm':V,'SweepTimes':T}\n",
        "\n",
        "def get_epoch(abf,epoch=3):\n",
        "    results={\"epoch\":epoch}\n",
        "    results={\"index\":{\"start\":abf.sweepEpochs.p1s[epoch],\n",
        "                      \"stop\":abf.sweepEpochs.p1s[epoch+1]}}\n",
        "    return results\n",
        "\n",
        "def analyze_currents(abf,start_idx,stop_idx,analysis_function=np.median,i_chan=0,v_chan=1):\n",
        "    I = list()\n",
        "    V = list()\n",
        "    for s in abf.sweepList:\n",
        "        abf.setSweep(s,channel=i_chan)\n",
        "        I.append(analysis_function(abf.sweepY[start_idx:stop_idx]))\n",
        "        abf.setSweep(s,channel=v_chan)\n",
        "        V.append(analysis_function(abf.sweepY[start_idx:stop_idx]))\n",
        "    V = [int(10*np.round(v/10,0)) for v in V]\n",
        "    return I,V,list(abf.sweepTimesSec)\n",
        "\n",
        "\n",
        "def linear_leak_correction(sweep_results,v_range=(-90,-30)):\n",
        "    Vm = np.array(sweep_results['Vm'])[:,np.newaxis]\n",
        "    I = np.array(sweep_results['Ik'])[:,np.newaxis]\n",
        "    fit_ind = [i for i,v in enumerate(Vm) if v >= np.min(v_range) and v<= np.max(v_range) ]\n",
        "    if len(fit_ind)<2:\n",
        "        sweep_results['I_leak'] = I*np.nan\n",
        "        sweep_results['Ik_corr'] =I*np.nan\n",
        "        return sweep_results\n",
        "    x = Vm[fit_ind]\n",
        "    y = I[fit_ind]\n",
        "    leak_model = linear_model.LinearRegression().fit(x,y)\n",
        "    leak_pred  = leak_model.predict(Vm)\n",
        "    corrected_I = I - leak_pred\n",
        "    corrected_I = [float(c) for c in corrected_I]\n",
        "    sweep_results['I_leak'] = leak_pred\n",
        "    sweep_results['Ik_corr'] =corrected_I\n",
        "    return sweep_results\n"
      ],
      "metadata": {
        "id": "y0L_Kh_iV3UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_plot = True\n",
        "results_list = list()\n",
        "for rec in abf_recordings_df.index:\n",
        "    abf = pyabf.ABF(rec)\n",
        "    sweep_results = measure_slick(abf,duration_ms = 10,to_plot=True)\n",
        "    if abf_recordings_df.loc[rec,'protocol'] == 'K_total':\n",
        "        abf = pyabf.ABF(rec)\n",
        "        sweep_results = linear_leak_correction(sweep_results)\n",
        "        fig_leak,ax= plt.subplots(1,figsize=(1.5,1),dpi=300)\n",
        "        ax.scatter(sweep_results['Vm'],sweep_results['Ik'],c='k',s=.1)\n",
        "        ax.plot(sweep_results['Vm'],sweep_results['I_leak'],'k',linewidth=.2)\n",
        "        ax.twinx().scatter(sweep_results['Vm'],sweep_results['Ik_corr'],c='r',s=.1)\n",
        "        name=rec.split('/')[-1]\n",
        "        ax.set_title(name)\n",
        "        fig_leak.savefig(f\"./figs/{name}_LEAK.svg\", format='svg',bbox_inches='tight')\n",
        "\n",
        "    results_list.append(sweep_results)\n",
        "abf_recordings_df['K_Currents']=results_list"
      ],
      "metadata": {
        "id": "mp_1103TN-x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "before_data =list()\n",
        "for cell_rec in doses_df['Before IV'].values:\n",
        "    for rec in abf_recordings_df.index:\n",
        "        if str(cell_rec) in rec:\n",
        "            before_data.append(abf_recordings_df.loc[rec,'K_Currents'])\n",
        "doses_df['Before'] = before_data\n",
        "\n",
        "\n",
        "after_data =list()\n",
        "for cell_rec in doses_df['After IV'].values:\n",
        "    for rec in abf_recordings_df.index:\n",
        "        if str(cell_rec) in rec:\n",
        "            after_data.append(abf_recordings_df.loc[rec,'K_Currents'])\n",
        "doses_df['After'] = after_data\n",
        "\n",
        "display(doses_df.head())"
      ],
      "metadata": {
        "id": "0D5oc1y_EDlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doses_df['delta']=pd.Series\n",
        "for r in doses_df.index:\n",
        "    before = doses_df.loc[r,'Before']\n",
        "    max_I = np.max(before['Ik_corr'])\n",
        "    before['Ik_norm'] = before['Ik_corr'] / max_I\n",
        "    doses_df.at[r,'Before'] = before\n",
        "\n",
        "    after = doses_df.loc[r,'After']\n",
        "    after['Ik_norm'] = after['Ik_corr'] / max_I\n",
        "    doses_df.at[r,'After'] = after\n",
        "\n",
        "    common = sorted(list(set(after['Vm']).intersection(set(before['Vm']))))\n",
        "\n",
        "    delta = {'Vm':common,'Ikb':list(),'Ika':list()}\n",
        "\n",
        "    for i,v in enumerate(before['Vm']):\n",
        "        if v in delta['Vm']:\n",
        "            delta['Ikb'].append( before['Ik_norm'][i] )\n",
        "\n",
        "    for i,v in enumerate(after['Vm']):\n",
        "        if v in delta['Vm']:\n",
        "            delta['Ika'].append( after['Ik_norm'][i] )\n",
        "    doses_df.at[r,'delta'] = delta\n"
      ],
      "metadata": {
        "id": "d81Dh_-7FK8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ik_after=pd.DataFrame()\n",
        "Ik_before=pd.DataFrame()\n",
        "for c in doses_df.index:\n",
        "    Ik_before[c] = pd.DataFrame(doses_df.loc[c,'delta']).set_index('Vm')['Ikb']\n",
        "    Ik_after[c] = pd.DataFrame(doses_df.loc[c,'delta']).set_index('Vm')['Ika']\n",
        "\n",
        "Ik_after.to_csv('Normalized_IV_10uM.csv')\n",
        "Ik_before.to_csv('Normalized_IV_Before.csv')\n",
        "from google import colab\n",
        "colab.files.download('Normalized_IV_10uM.csv')\n",
        "colab.files.download('Normalized_IV_Before.csv')"
      ],
      "metadata": {
        "id": "nQA3e9X-11qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig_IV_block,ax=plt.subplots(1,dpi=300,figsize=(3,2))\n",
        "ax.errorbar(Ik_after.index,\n",
        "            np.mean(Ik_before.T),\n",
        "            yerr = scipy.stats.sem(Ik_before,axis=1),fmt ='.-',\n",
        "            markersize=3, c='k',\n",
        "            linewidth=1,\n",
        "            capsize=1,\n",
        "            label='aCSF')\n",
        "\n",
        "ax.errorbar(Ik_after.index,\n",
        "            np.mean(Ik_after.T),\n",
        "            yerr = scipy.stats.sem(Ik_after,axis=1),fmt ='.-',\n",
        "            markersize=3, c='r',\n",
        "            linewidth=1,\n",
        "            capsize=1,zorder=0,\n",
        "            label='BMX 10uM')\n",
        "ax.axhline(0,linewidth=.1,color='k')\n",
        "ax.axvline(0,linewidth=.1,color='k')\n",
        "plt.legend()\n",
        "ax.set_ylabel('Relative K$^+$ Current')\n",
        "ax.set_xlabel('V$_m$ (mV)')\n",
        "# ax.spines['left'].set_position('zero')\n",
        "# ax.spines['right'].set_color('none')\n",
        "# ax.spines['bottom'].set_position('zero')\n",
        "# ax.spines['top'].set_color('none')\n",
        "# ax.xaxis.set_ticks_position('bottom')\n",
        "# ax.yaxis.set_ticks_position('left')\n",
        "fig_IV_block.savefig('./figs/fig_IV_block.svg',format='svg',bbox_inches='tight')\n",
        "colab.files.download('./figs/fig_IV_block.svg')"
      ],
      "metadata": {
        "id": "FUiMQ7nFbtNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def slick_sub(abf):\n",
        "    duration_ms =10\n",
        "    duration_indx = int(duration_ms/1000*abf.sampleRate)\n",
        "\n",
        "    abf = pyabf.ABF(file_loc)\n",
        "    measure_epoch_1 = get_epoch(abf,epoch=1)\n",
        "    abf = pyabf.ABF(file_loc)\n",
        "    measure_epoch_2 = get_epoch(abf,epoch=2)\n",
        "    abf = pyabf.ABF(file_loc)\n",
        "    measure_epoch_3 = get_epoch(abf,epoch=3)\n",
        "\n",
        "    I_1,V_1,T = analyze_currents(abf,measure_epoch_1['index'][\"stop\"]-duration_indx,measure_epoch_1['index'][\"stop\"],i_chan=0)\n",
        "    I_2,V_2,T = analyze_currents(abf,measure_epoch_2['index'][\"stop\"]-duration_indx,measure_epoch_2['index'][\"stop\"],i_chan=0)\n",
        "    I_3,V_3,T = analyze_currents(abf,measure_epoch_3['index'][\"stop\"]-duration_indx,measure_epoch_3['index'][\"stop\"],i_chan=0)\n",
        "\n",
        "    dv_2 = np.array(V_2) - np.array(V_1)\n",
        "    dv_3 = np.array(V_3) - np.array(V_1)\n",
        "    di_2 = np.array(I_2) - np.array(I_1)\n",
        "    L = di_2*(dv_3/dv_2)  + I_1\n",
        "    I_corr = I_3-L\n",
        "    return (I_corr,V_3,T)"
      ],
      "metadata": {
        "id": "x6MbJLIYjrj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wash_in_data=list()\n",
        "for c in doses_df.index:\n",
        "    rec_id = doses_df.loc[c,'During']\n",
        "    file_loc = [f for f in abf_recordings_df.index if rec_id in f][0]\n",
        "    doses_df.loc[c,'ABF'] = file_loc\n",
        "    abf = pyabf.ABF(file_loc)\n",
        "\n",
        "    duration_ms = 10\n",
        "    duration_indx = int(duration_ms/1000*abf.sampleRate)\n",
        "    measure_epoch = get_epoch(abf,epoch=3)\n",
        "    stop_idx = measure_epoch['index'][\"stop\"]\n",
        "    start_idx = stop_idx - duration_indx\n",
        "\n",
        "    if 2 not in abf.channelList:\n",
        "        I,V,T = analyze_currents(abf,start_idx,stop_idx,i_chan=0)\n",
        "        I = [i*np.nan for i in I]\n",
        "    if 2 in abf.channelList:\n",
        "        I,V,T = analyze_currents(abf,start_idx,stop_idx,i_chan=2)\n",
        "        trace = {\"current\":I,\"Vm\":V,\"Time\":T}\n",
        "\n",
        "    wash_in_data.append(I/np.mean(I[:4]))\n",
        "doses_df['wash_in_data']=wash_in_data\n"
      ],
      "metadata": {
        "id": "m_5TtdvN_pDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skip_list = ['2023x12x14_SLICK_c001_HEK','2023x12x15_SLICK_c003_HEK',]\n",
        "# skip_list=[]\n",
        "wash_in_df=pd.DataFrame()\n",
        "for c in doses_df.index:\n",
        "    if c not in skip_list:\n",
        "        wash_in_df[c] = pd.DataFrame(doses_df.loc[c,'wash_in_data'])\n",
        "\n",
        "\n",
        "fig_wash_in,ax = plt.subplots(1,figsize=(2,1))\n",
        "x = wash_in_df.index*5/60\n",
        "y = np.nanmean(wash_in_df,axis=1)\n",
        "err = scipy.stats.sem(wash_in_df,axis=1,nan_policy='omit')\n",
        "\n",
        "ax.errorbar(x,\n",
        "            y,\n",
        "            yerr = err,\n",
        "            fmt ='.-',\n",
        "            markersize=3, c='k',\n",
        "            linewidth=1,\n",
        "            capsize=1)\n",
        "ax.axhline(1,color='k',linewidth=.5)\n",
        "bmx_dur=(.4,np.max(x))\n",
        "bmx_bar_h = 1.25\n",
        "ax.plot(bmx_dur,[bmx_bar_h]*2,'r',linewidth=1.2)\n",
        "ax.text(np.mean(bmx_dur),bmx_bar_h,'BMX 10uM',ha='center',va='bottom',color='r')\n",
        "\n",
        "ax.set_ylim(-.1,1.45)\n",
        "wash_in_df.to_csv('wash_in_df.csv')\n",
        "colab.files.download('wash_in_df.csv')\n",
        "ax.set_ylabel('Relative K$^+$ Current')\n",
        "ax.set_xlabel('Time (min)')\n",
        "fig_wash_in.savefig(\"./figs/fig_wash_in.svg\", format='svg',bbox_inches='tight')\n",
        "colab.files.download('./figs/fig_wash_in.svg')"
      ],
      "metadata": {
        "id": "2kqECHPbTZE6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}