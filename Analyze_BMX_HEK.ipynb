{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfae32FeR3ThjduTWPbiDw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtabuena/Ephys_DataSets/blob/main/Analyze_BMX_HEK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N5Bsqf_jeQjZ",
        "outputId": "442a32f8-26d3-45c8-cba2-0e71a04f5958",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Collecting XlsxWriter\n",
            "  Downloading XlsxWriter-3.1.9-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter\n",
            "Successfully installed XlsxWriter-3.1.9\n",
            "Cloning into 'EphysLib'...\n",
            "remote: Enumerating objects: 1141, done.\u001b[K\n",
            "remote: Counting objects: 100% (518/518), done.\u001b[K\n",
            "remote: Compressing objects: 100% (247/247), done.\u001b[K\n",
            "remote: Total 1141 (delta 377), reused 359 (delta 271), pack-reused 623\u001b[K\n",
            "Receiving objects: 100% (1141/1141), 17.41 MiB | 18.27 MiB/s, done.\n",
            "Resolving deltas: 100% (754/754), done.\n",
            "Collecting pyabf\n",
            "  Downloading pyabf-2.3.8-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pyabf) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from pyabf) (1.23.5)\n",
            "Requirement already satisfied: pytest>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from pyabf) (7.4.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pyabf) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pyabf) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pyabf) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pyabf) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pyabf) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pyabf) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pyabf) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pyabf) (2.8.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=3.0.7->pyabf) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.0.7->pyabf) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.0.7->pyabf) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.0.7->pyabf) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pyabf) (1.16.0)\n",
            "Installing collected packages: pyabf\n",
            "Successfully installed pyabf-2.3.8\n"
          ]
        }
      ],
      "source": [
        "'Get Standard Modules'\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from scipy import stats\n",
        "import os\n",
        "from scipy.signal import butter,filtfilt\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "from IPython.display import clear_output\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import warnings\n",
        "import shutil\n",
        "from google.colab import files\n",
        "warnings.filterwarnings('ignore')\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "clear_output(wait=False)\n",
        "\n",
        "\n",
        "\n",
        "!pip install openpyxl\n",
        "!pip install XlsxWriter\n",
        "\n",
        "\n",
        "'''Get Repositories'''\n",
        "try: shutil.rmtree('/content/EphysLib')\n",
        "except: None\n",
        "\n",
        "\"run dtabuena's ephys notebooks\"\n",
        "!git clone https://github.com/dtabuena/EphysLib\n",
        "to_import = [\n",
        "            'ABF_Quality_Control.ipynb',\n",
        "            'Basic_Ephys.ipynb',\n",
        "            'Simple_ABF_tools.ipynb',\n",
        "            'fun_math.ipynb',\n",
        "            'importing_abfs_from_dropbox.ipynb',\n",
        "            'QC_recoding_dataframe.ipynb',\n",
        "            'Analyzers/input_resistance_analyzer.ipynb',\n",
        "            'Analyzers/gain_analyzer.ipynb',\n",
        "            'Analyzers/latencey_analyzer.ipynb',\n",
        "            'Analyzers/IV_analyzer.ipynb',\n",
        "            'Analyzers/Vm_analyzer.ipynb',\n",
        "            'Analyzers/membrane_analyzer.ipynb',\n",
        "            'Analyzers/rheobase_analyzer.ipynb',\n",
        "\n",
        "            'Ephys_wrapper.ipynb',\n",
        "            ]\n",
        "for i in to_import:\n",
        "    f = '/content/EphysLib/' + i\n",
        "    %run $f\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### quick import\n",
        "import urllib\n",
        "import json\n",
        "import matplotlib as mpl\n",
        "from matplotlib import rcParams\n",
        "def import_mpl_config(FS=6):\n",
        "    \"\"\" Load my default plotting parameters \"\"\"\n",
        "    if os.path.isfile(f'./mpl_config_FS{FS}.json'):\n",
        "        os.remove(f'./mpl_config_FS{FS}.json')\n",
        "    _ = urllib.request.urlretrieve('https://github.com/dtabuena/Resources/'\\\n",
        "                                   'raw//main/Matplotlib_Config/'\\\n",
        "                                   f'mpl_config_FS{FS}.json',\n",
        "                                   f'mpl_config_FS{FS}.json')\n",
        "    with open(f\"./mpl_config_FS{FS}.json\",'r') as import_file:\n",
        "        fig_config = json.load(import_file)\n",
        "    rcParams.update(fig_config)\n",
        "    _ = urllib.request.urlretrieve('https://github.com/dtabuena/Resources/raw/main/Fonts/arial.ttf','arial.ttf')\n",
        "    mpl.font_manager.fontManager.addfont('arial.ttf')\n",
        "    return fig_config\n",
        "_ = import_mpl_config()"
      ],
      "metadata": {
        "id": "3k_zR7QphuYn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "file_name,_ = urllib.request.urlretrieve('https://www.dropbox.com/scl/fi/1yg80je83aqr68berui86/Before_After.csv?rlkey=k9pacq5t9u9icu1nkcnrhoad6&dl=1','before_after.csv')\n",
        "doses_df = pd.read_csv(file_name).set_index('Cell')\n",
        "display(doses_df.head(15))"
      ],
      "metadata": {
        "id": "iHdSeg2QT5nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = {'data_name': 'BMX',\n",
        "           'data_source': \"https://www.dropbox.com/scl/fo/2ps1mdb88490cgol95l3u/h?rlkey=trp33s4fhrl4pyg4h4k0jecwh&dl=1\",\n",
        "           'file_naming_scheme': ['Rec_date','GenoType','Cell_num','Cell_Type'],\n",
        "           }\n",
        "##2023x12x13_SLICK_c001_HEK_0001\n",
        "data_name = dataset['data_name']\n",
        "data_source = dataset['data_source']\n",
        "file_naming_scheme = dataset['file_naming_scheme']\n",
        "\n",
        "''' Gather and Catalog Source Data'''\n",
        "file_loc = get_drobox_folder_url(data_source, 'my_ephys_data_' + data_name)\n",
        "clear_output(wait=False)\n",
        "abf_recordings_df, protocol_set = catalogue_recs(file_loc,file_naming_scheme)\n",
        "print(protocol_set)"
      ],
      "metadata": {
        "id": "7tcKwC6keh7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('figs'): os.makedirs('figs')"
      ],
      "metadata": {
        "id": "95DCzbAThC4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "def measure_slick(abf,duration_ms = 10,to_plot=True):\n",
        "    i_chan = 0\n",
        "    duration_indx = int(duration_ms/1000*abf.sampleRate)\n",
        "    measure_epoch = get_epoch(abf,epoch=3)\n",
        "    stop_idx = measure_epoch['index'][\"stop\"]\n",
        "    start_idx = stop_idx - duration_indx\n",
        "    # if 2 in abf.channelList: i_chan = 2\n",
        "    I,V,T = analyze_currents(abf,start_idx,stop_idx,i_chan=i_chan)\n",
        "    return {'Ik':I,'Vm':V,'SweepTimes':T}\n",
        "\n",
        "def get_epoch(abf,epoch=3):\n",
        "    results={\"epoch\":epoch}\n",
        "    results={\"index\":{\"start\":abf.sweepEpochs.p1s[epoch],\n",
        "                      \"stop\":abf.sweepEpochs.p1s[epoch+1]}}\n",
        "    return results\n",
        "\n",
        "def analyze_currents(abf,start_idx,stop_idx,analysis_function=np.median,i_chan=0,v_chan=1):\n",
        "    I = list()\n",
        "    V = list()\n",
        "    for s in abf.sweepList:\n",
        "        abf.setSweep(s,channel=i_chan)\n",
        "        I.append(analysis_function(abf.sweepY[start_idx:stop_idx]))\n",
        "        abf.setSweep(s,channel=v_chan)\n",
        "        V.append(analysis_function(abf.sweepY[start_idx:stop_idx]))\n",
        "    V = [int(10*np.round(v/10,0)) for v in V]\n",
        "    return I,V,list(abf.sweepTimesSec)\n",
        "\n",
        "\n",
        "def linear_leak_correction(sweep_results,v_range=(-90,-30)):\n",
        "    Vm = np.array(sweep_results['Vm'])[:,np.newaxis]\n",
        "    I = np.array(sweep_results['Ik'])[:,np.newaxis]\n",
        "    fit_ind = [i for i,v in enumerate(Vm) if v >= np.min(v_range) and v<= np.max(v_range) ]\n",
        "    if len(fit_ind)<2:\n",
        "        sweep_results['I_leak'] = I*np.nan\n",
        "        sweep_results['Ik_corr'] =I*np.nan\n",
        "        return sweep_results\n",
        "    x = Vm[fit_ind]\n",
        "    y = I[fit_ind]\n",
        "    leak_model = linear_model.LinearRegression().fit(x,y)\n",
        "    leak_pred  = leak_model.predict(Vm)\n",
        "    corrected_I = I - leak_pred\n",
        "    corrected_I = [float(c) for c in corrected_I]\n",
        "    sweep_results['I_leak'] = leak_pred\n",
        "    sweep_results['Ik_corr'] =corrected_I\n",
        "    return sweep_results\n"
      ],
      "metadata": {
        "id": "y0L_Kh_iV3UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_plot = True\n",
        "results_list = list()\n",
        "for rec in abf_recordings_df.index:\n",
        "    abf = pyabf.ABF(rec)\n",
        "    sweep_results = measure_slick(abf,duration_ms = 10,to_plot=True)\n",
        "    if abf_recordings_df.loc[rec,'protocol'] == 'K_total':\n",
        "        abf = pyabf.ABF(rec)\n",
        "        sweep_results = linear_leak_correction(sweep_results)\n",
        "        fig_leak,ax= plt.subplots(1,figsize=(1.5,1),dpi=300)\n",
        "        ax.scatter(sweep_results['Vm'],sweep_results['Ik'],c='k',s=.1)\n",
        "        ax.plot(sweep_results['Vm'],sweep_results['I_leak'],'k',linewidth=.2)\n",
        "        ax.twinx().scatter(sweep_results['Vm'],sweep_results['Ik_corr'],c='r',s=.1)\n",
        "        name=rec.split('/')[-1]\n",
        "        ax.set_title(name)\n",
        "        fig_leak.savefig(f\"./figs/{name}_LEAK.svg\", format='svg',bbox_inches='tight')\n",
        "\n",
        "    results_list.append(sweep_results)\n",
        "abf_recordings_df['K_Currents']=results_list"
      ],
      "metadata": {
        "id": "mp_1103TN-x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "before_data =list()\n",
        "for cell_rec in doses_df['Before IV'].values:\n",
        "    for rec in abf_recordings_df.index:\n",
        "        if str(cell_rec) in rec:\n",
        "            before_data.append(abf_recordings_df.loc[rec,'K_Currents'])\n",
        "doses_df['Before'] = before_data\n",
        "\n",
        "\n",
        "after_data =list()\n",
        "for cell_rec in doses_df['After IV'].values:\n",
        "    for rec in abf_recordings_df.index:\n",
        "        if str(cell_rec) in rec:\n",
        "            after_data.append(abf_recordings_df.loc[rec,'K_Currents'])\n",
        "doses_df['After'] = after_data\n",
        "\n",
        "display(doses_df.head())"
      ],
      "metadata": {
        "id": "0D5oc1y_EDlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doses_df['delta']=pd.Series\n",
        "for r in doses_df.index:\n",
        "    before = doses_df.loc[r,'Before']\n",
        "    max_I = np.max(before['Ik_corr'])\n",
        "    before['Ik_norm'] = before['Ik_corr'] / max_I\n",
        "    doses_df.at[r,'Before'] = before\n",
        "\n",
        "    after = doses_df.loc[r,'After']\n",
        "    after['Ik_norm'] = after['Ik_corr'] / max_I\n",
        "    doses_df.at[r,'After'] = after\n",
        "\n",
        "    common = sorted(list(set(after['Vm']).intersection(set(before['Vm']))))\n",
        "\n",
        "    delta = {'Vm':common,'Ikb':list(),'Ika':list()}\n",
        "\n",
        "    for i,v in enumerate(before['Vm']):\n",
        "        if v in delta['Vm']:\n",
        "            delta['Ikb'].append( before['Ik_norm'][i] )\n",
        "\n",
        "    for i,v in enumerate(after['Vm']):\n",
        "        if v in delta['Vm']:\n",
        "            delta['Ika'].append( after['Ik_norm'][i] )\n",
        "    doses_df.at[r,'delta'] = delta\n"
      ],
      "metadata": {
        "id": "d81Dh_-7FK8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ik_after=pd.DataFrame()\n",
        "Ik_before=pd.DataFrame()\n",
        "for c in doses_df.index:\n",
        "    Ik_before[c] = pd.DataFrame(doses_df.loc[c,'delta']).set_index('Vm')['Ikb']\n",
        "    Ik_after[c] = pd.DataFrame(doses_df.loc[c,'delta']).set_index('Vm')['Ika']\n",
        "\n",
        "Ik_after.to_csv('Normalized_IV_10uM.csv')\n",
        "Ik_before.to_csv('Normalized_IV_Before.csv')\n",
        "from google import colab\n",
        "colab.files.download('Normalized_IV_10uM.csv')\n",
        "colab.files.download('Normalized_IV_Before.csv')"
      ],
      "metadata": {
        "id": "nQA3e9X-11qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig_IV_block,ax=plt.subplots(1,dpi=300,figsize=(3,2))\n",
        "ax.errorbar(Ik_after.index,\n",
        "            np.mean(Ik_before.T),\n",
        "            yerr = scipy.stats.sem(Ik_before,axis=1),fmt ='.-',\n",
        "            markersize=3, c='k',\n",
        "            linewidth=1,\n",
        "            capsize=1,\n",
        "            label='aCSF')\n",
        "\n",
        "ax.errorbar(Ik_after.index,\n",
        "            np.mean(Ik_after.T),\n",
        "            yerr = scipy.stats.sem(Ik_after,axis=1),fmt ='.-',\n",
        "            markersize=3, c='r',\n",
        "            linewidth=1,\n",
        "            capsize=1,zorder=0,\n",
        "            label='BMX 10uM')\n",
        "ax.axhline(0,linewidth=.1,color='k')\n",
        "ax.axvline(0,linewidth=.1,color='k')\n",
        "plt.legend()\n",
        "ax.set_ylabel('Relative K$^+$ Current')\n",
        "ax.set_xlabel('V$_m$ (mV)')\n",
        "# ax.spines['left'].set_position('zero')\n",
        "# ax.spines['right'].set_color('none')\n",
        "# ax.spines['bottom'].set_position('zero')\n",
        "# ax.spines['top'].set_color('none')\n",
        "# ax.xaxis.set_ticks_position('bottom')\n",
        "# ax.yaxis.set_ticks_position('left')\n",
        "fig_IV_block.savefig('./figs/fig_IV_block.svg',format='svg',bbox_inches='tight')"
      ],
      "metadata": {
        "id": "FUiMQ7nFbtNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def slick_sub(abf):\n",
        "    duration_ms =10\n",
        "    duration_indx = int(duration_ms/1000*abf.sampleRate)\n",
        "\n",
        "    abf = pyabf.ABF(file_loc)\n",
        "    measure_epoch_1 = get_epoch(abf,epoch=1)\n",
        "    abf = pyabf.ABF(file_loc)\n",
        "    measure_epoch_2 = get_epoch(abf,epoch=2)\n",
        "    abf = pyabf.ABF(file_loc)\n",
        "    measure_epoch_3 = get_epoch(abf,epoch=3)\n",
        "\n",
        "    I_1,V_1,T = analyze_currents(abf,measure_epoch_1['index'][\"stop\"]-duration_indx,measure_epoch_1['index'][\"stop\"],i_chan=0)\n",
        "    I_2,V_2,T = analyze_currents(abf,measure_epoch_2['index'][\"stop\"]-duration_indx,measure_epoch_2['index'][\"stop\"],i_chan=0)\n",
        "    I_3,V_3,T = analyze_currents(abf,measure_epoch_3['index'][\"stop\"]-duration_indx,measure_epoch_3['index'][\"stop\"],i_chan=0)\n",
        "\n",
        "    dv_2 = np.array(V_2) - np.array(V_1)\n",
        "    dv_3 = np.array(V_3) - np.array(V_1)\n",
        "    di_2 = np.array(I_2) - np.array(I_1)\n",
        "    L = di_2*(dv_3/dv_2)  + I_1\n",
        "    I_corr = I_3-L\n",
        "    return (I_corr,V_3,T)"
      ],
      "metadata": {
        "id": "x6MbJLIYjrj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wash_in_data=list()\n",
        "for c in doses_df.index:\n",
        "    rec_id = doses_df.loc[c,'During']\n",
        "    file_loc = [f for f in abf_recordings_df.index if rec_id in f][0]\n",
        "    doses_df.loc[c,'ABF'] = file_loc\n",
        "    abf = pyabf.ABF(file_loc)\n",
        "    if 2 not in abf.channelList:\n",
        "        I,V,T = analyze_currents(abf,start_idx,stop_idx,i_chan=0)\n",
        "        I = [i*np.nan for i in I]\n",
        "    if 2 in abf.channelList:\n",
        "        duration_ms = 10\n",
        "        duration_indx = int(duration_ms/1000*abf.sampleRate)\n",
        "        measure_epoch = get_epoch(abf,epoch=3)\n",
        "        stop_idx = measure_epoch['index'][\"stop\"]\n",
        "        start_idx = stop_idx - duration_indx\n",
        "        I,V,T = analyze_currents(abf,start_idx,stop_idx,i_chan=2)\n",
        "        trace = {\"current\":I,\"Vm\":V,\"Time\":T}\n",
        "\n",
        "    wash_in_data.append(I/np.mean(I[:4]))\n",
        "doses_df['wash_in_data']=wash_in_data\n"
      ],
      "metadata": {
        "id": "m_5TtdvN_pDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TeZm5k17lTna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c"
      ],
      "metadata": {
        "id": "AKCgJlE8pCBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wash_in_df"
      ],
      "metadata": {
        "id": "hCUQLgE3pOxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skip_list = ['2023x12x14_SLICK_c001_HEK','2023x12x15_SLICK_c003_HEK',]\n",
        "wash_in_df=pd.DataFrame()\n",
        "for c in doses_df.index:\n",
        "    if c not in skip_list:\n",
        "        wash_in_df[c] = pd.DataFrame(doses_df.loc[c,'wash_in_data'])\n",
        "\n",
        "\n",
        "fig_wash_in,ax = plt.subplots(1,figsize=(2,1))\n",
        "x = wash_in_df.index*5/60\n",
        "y = np.nanmean(wash_in_df,axis=1)\n",
        "err = scipy.stats.sem(wash_in_df,axis=1,nan_policy='omit')\n",
        "\n",
        "ax.errorbar(x,\n",
        "            y,\n",
        "            yerr = err,\n",
        "            fmt ='.-',\n",
        "            markersize=3, c='k',\n",
        "            linewidth=1,\n",
        "            capsize=1)\n",
        "ax.axhline(1,color='k',linewidth=.5)\n",
        "ax.set_ylim(-.1,1.2)\n",
        "wash_in_df.to_csv('wash_in_df.csv')\n",
        "colab.files.download('wash_in_df.csv')\n",
        "ax.set_ylabel('Relative K$^+$ Current')\n",
        "ax.set_xlabel('Time (min)')\n",
        "fig_wash_in.savefig(\"./figs/fig_wash_in.svg\", format='svg',bbox_inches='tight')"
      ],
      "metadata": {
        "id": "2kqECHPbTZE6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}